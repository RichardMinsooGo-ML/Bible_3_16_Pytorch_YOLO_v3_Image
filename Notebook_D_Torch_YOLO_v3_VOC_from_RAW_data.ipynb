{"cells":[{"cell_type":"markdown","metadata":{"id":"NXAPw1n-6D10"},"source":["# 1. [Opt] Check GPU Type"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":591,"status":"ok","timestamp":1670461940505,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"},"user_tz":-540},"outputId":"819a3033-03a0-4e1b-9484-9b1e1f152267","id":"Fwgit9Bi6D10"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Dec  8 01:12:19 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P0    27W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# Check GPU Type\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","    print('and then re-execute this cell.')\n","else:\n","    print(gpu_info)"]},{"cell_type":"markdown","metadata":{"id":"HtbZBWeM6D11"},"source":["# 2. Git Clone from Github Repository to root directory\n","At Colab, location is \"/content/\".\n","\n","Using `$ git clone https://github.com/lainyzine/git-clone.git` will load the Github repository with the name of the repository. With Colab, it can be convenient to work in the root directory. You can use the command to call the root directory as shown below.\n","\n","According to the Github repository, we can use `! git pull origin main` or `! Just use git pull origin master`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5480,"status":"ok","timestamp":1670461945980,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"},"user_tz":-540},"outputId":"aaf8f0aa-4490-4921-e0ec-07f060cade9c","id":"JPl6VnQq6D11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initialized empty Git repository in /content/.git/\n","remote: Enumerating objects: 1948, done.\u001b[K\n","remote: Counting objects: 100% (89/89), done.\u001b[K\n","remote: Compressing objects: 100% (86/86), done.\u001b[K\n","remote: Total 1948 (delta 49), reused 2 (delta 2), pack-reused 1859\u001b[K\n","Receiving objects: 100% (1948/1948), 58.68 MiB | 17.40 MiB/s, done.\n","Resolving deltas: 100% (806/806), done.\n","From https://github.com/RichardMinsooGo-ML/Bible_3_16_Pytorch_YOLO_v3_Image\n"," * branch            main       -> FETCH_HEAD\n"," * [new branch]      main       -> origin/main\n"]}],"source":["# Clone from Github Repository\n","! git init .\n","! git remote add origin https://github.com/RichardMinsooGo-ML/Bible_3_21_Pytorch_YOLO_v3_Image.git\n","# ! git pull origin master\n","! git pull origin main"]},{"cell_type":"markdown","source":["# 3. import clear_output"],"metadata":{"id":"ePIBNpzm6D11"}},{"cell_type":"code","source":["from IPython.display import clear_output \n","clear_output()"],"metadata":{"id":"RrjfGKKq6D11"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Data Engineering from VOC RAW Dataset"],"metadata":{"id":"2vHx5Vtl6D11"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xHHX8CCr6D11"},"outputs":[],"source":["'''\n","4. Data Engineering from VOC RAW Dataset\n","'''\n","!pip install --upgrade --no-cache-dir gdown\n","\n","import gdown\n","\n","!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n","# ! mkdir dataset\n","!tar -xvf VOCtrainval_11-May-2012.tar -C /content/dataset\n","! rm /content/VOCtrainval_11-May-2012.tar\n","\n","clear_output()\n","\n","\n","# train valid list file generation\n","import os\n","\n","str_train = open(\"tmp_train.txt\", \"w\")\n","str_test  = open(\"tmp_val.txt\", \"w\")\n","\n","count = 0\n","for path, subdirs, files in os.walk(r\"/content/dataset/VOCdevkit/VOC2012/Annotations\"):\n","    for filename in files:\n","        f = os.path.join(filename)\n","        f = os.path.splitext(f)[0]\n","        \n","        count += 1\n","        if count%5 == 0:\n","            str_test.write(\"/content/dataset/VOC2012/images/\" + str(f) +\".jpg\"+ os.linesep)\n","        else:\n","            str_train.write(\"/content/dataset/VOC2012/images/\" + str(f) +\".jpg\"+ os.linesep)\n","        # str_train.write(str(f))\n","        \n","with open('tmp_train.txt') as infile, open('/content/dataset/VOC2012/train.txt', 'w') as outfile:\n","    for line in infile:\n","        if not line.strip(): continue  # skip the empty line\n","        outfile.write(line)  # non-empty line. Write it to output\n","with open('tmp_val.txt') as infile, open('/content/dataset/VOC2012/valid.txt', 'w') as outfile:\n","    for line in infile:\n","        if not line.strip(): continue  # skip the empty line\n","        outfile.write(line)  # non-empty line. Write it to output\n","\n","! rm tmp_train.txt\n","! rm tmp_val.txt       \n","\n","path = \"/content/dataset/VOC2012/images/\"\n","os.mkdir(path)\n","path = \"/content/dataset/VOC2012/labels/\"\n","os.mkdir(path)\n","path = \"/content/dataset/VOC2012/xml_files/\"\n","os.mkdir(path)\n","\n","# move files \n","import os\n","import shutil\n","\n","source_folder = r\"/content/dataset/VOCdevkit/VOC2012/JPEGImages//\"\n","destination_folder = r\"/content/dataset/VOC2012/images//\"\n","\n","# fetch all files\n","for file_name in os.listdir(source_folder):\n","    # construct full file path\n","    source = source_folder + file_name\n","    destination = destination_folder + file_name\n","    # move only files\n","    if os.path.isfile(source):\n","        shutil.move(source, destination)\n","        print('Moved:', file_name)\n","\n","source_folder = r\"/content/dataset/VOCdevkit/VOC2012/Annotations//\"\n","destination_folder = r\"/content/dataset/VOC2012/xml_files//\"\n","# fetch all files\n","for file_name in os.listdir(source_folder):\n","    # construct full file path\n","    source = source_folder + file_name\n","    destination = destination_folder + file_name\n","    # move only files\n","    if os.path.isfile(source):\n","        shutil.move(source, destination)\n","        print('Moved:', file_name)\n","\n","clear_output()\n","\n","shutil.rmtree(\"/content/dataset/VOCdevkit\")\n","\n","# Create VOC Dataset form\n","\"\"\"\n","출처: https://github.com/pjreddie/darknet/blob/master/scripts/voc_label.py\n","\n","Pascal VOC의 원본 annotation을 Yolo v3의 Object Detection label format으로 변환해주는 스크립트입니다.\n","이 파일을 VOCdevkit의 상위폴더로 옮긴 후, 해당 폴더에서 아래 명령을 실행하십시오.\n","    python voc_label.py\n","\n","출력되는 파일은 아래와 같습니다.\n","    2007_test.txt\n","    train.txt\n","    voc_classes.txt\n","2007_test.txt, train.txt 파일을 열어보면 이미지들의 위치가 절대경로로 적혀있습니다.\n","만약 상대경로로 바꿔주려면 VSCode에서 알맞게 변환해줍니다.\n","\"\"\"\n","\n","import os\n","import xml.etree.ElementTree as ET\n","import numpy as np\n","\n","# classes = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n","\n","classes = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n","\n","def convert(size, box):\n","    dw = 1. / (size[0])\n","    dh = 1. / (size[1])\n","    x = (box[0] + box[1]) / 2.0 - 1\n","    y = (box[2] + box[3]) / 2.0 - 1\n","    w = box[1] - box[0]\n","    h = box[3] - box[2]\n","    x = x * dw\n","    w = w * dw\n","    y = y * dh\n","    h = h * dh\n","    return x, y, w, h\n","\n","def convert_annotation(image_id):\n","    in_file  = open('/content/dataset/VOC2012/xml_files/%s.xml'%(image_id))\n","    out_file = open('/content/dataset/VOC2012/labels/%s.txt'%(image_id), 'w')\n","    # in_file  = open('COCO2017/Annotations/%s.xml'%(image_id))\n","    # out_file = open('COCO2017/labels/%s.txt'%(image_id), 'w')\n","    tree = ET.parse(in_file)\n","    root = tree.getroot()\n","    size = root.find('size')\n","    w = int(size.find('width').text)\n","    h = int(size.find('height').text)\n","\n","    for obj in root.iter('object'):\n","        difficult = obj.find('difficult').text\n","        cls = obj.find('name').text\n","        if cls not in classes or int(difficult) == 1:\n","            continue\n","        cls_id = classes.index(cls)\n","        xmlbox = obj.find('bndbox')\n","        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text),\n","             float(xmlbox.find('ymax').text))\n","        bb = convert((w, h), b)\n","        \n","        bb = np.around(bb, decimals=6)\n","        \n","        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n","\n","sets = [('train'), ('valid')]\n","\n","if __name__ == '__main__':\n","    wd = os.getcwd()\n","\n","    for image_set in sets:\n","        image_ids = open('/content/dataset/VOC2012/%s.txt' % (image_set)).read().strip().split()\n","        for image_id in image_ids:\n","            \n","            image_id = image_id.split(\"/\")\n","            image_id = image_id[5]\n","            image_id = image_id.split(\".\")\n","            image_id = image_id[0]\n","            \n","            # print(image_id)\n","            \n","            convert_annotation(image_id)\n","        # list_file.close()\n","          \n","clear_output()\n","\n","# Zip Dataset \n","# !zip -r /content/file.zip /content/dataset/VOC2012/labels"]},{"cell_type":"markdown","source":["# 5. [Opt] Check Memory Space"],"metadata":{"id":"RjvPmiyH6D12"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670462190049,"user_tz":-540,"elapsed":4,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"295d4d9c-fb2b-42ab-ec12-b4761b210b7f","id":"P53CIbnE6D12"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}],"source":["# Memory Space\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","    print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","    print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","    print('re-execute this cell.')\n","else:\n","    print('You are using a high-RAM runtime!')"]},{"cell_type":"markdown","source":["# 6. install terminaltables for Ascii Table print"],"metadata":{"id":"tX39lSxf4bZm"}},{"cell_type":"code","source":["!pip install terminaltables"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bqIxjxB4ZGf","executionInfo":{"status":"ok","timestamp":1670462193941,"user_tz":-540,"elapsed":3894,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"031b3244-4706-4f25-ff3c-d260890ec76c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting terminaltables\n","  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n","Installing collected packages: terminaltables\n","Successfully installed terminaltables-3.1.10\n"]}]},{"cell_type":"markdown","source":["# 7. Download Darknet Weights"],"metadata":{"id":"KVFw_fUW6D12"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14873,"status":"ok","timestamp":1670462208811,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"},"user_tz":-540},"outputId":"d400cdbf-c050-4ff8-9dd3-2b429c1e348c","id":"1OVQPIOM6D12"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-08 01:16:33--  https://pjreddie.com/media/files/yolov3-tiny.weights\n","Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n","Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 35434956 (34M) [application/octet-stream]\n","Saving to: ‘yolov3-tiny.weights’\n","\n","yolov3-tiny.weights 100%[===================>]  33.79M  15.6MB/s    in 2.2s    \n","\n","2022-12-08 01:16:36 (15.6 MB/s) - ‘yolov3-tiny.weights’ saved [35434956/35434956]\n","\n","--2022-12-08 01:16:36--  https://pjreddie.com/media/files/yolov3.weights\n","Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n","Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 248007048 (237M) [application/octet-stream]\n","Saving to: ‘yolov3.weights’\n","\n","yolov3.weights      100%[===================>] 236.52M  23.1MB/s    in 11s     \n","\n","2022-12-08 01:16:47 (21.5 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n","\n"]}],"source":["# Download Darknet Weights\n","# ! wget https://pjreddie.com/media/files/yolo-voc.weights \n","! wget https://pjreddie.com/media/files/yolov3-tiny.weights \n","! wget https://pjreddie.com/media/files/yolov3.weights\n","# ! wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights \n","# ! wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights\n","\n","import shutil\n","shutil.move(\"/content/yolov3-tiny.weights\", \"/content/checkpoints\")\n","shutil.move(\"/content/yolov3.weights\", \"/content/checkpoints\")\n","# shutil.move(\"/content/yolov4-tiny.weights\", \"/content/tmp\")\n","# shutil.move(\"/content/yolov4.weights\", \"/content/tmp\") \n","shutil.rmtree(\"sample_data\")\n"]},{"cell_type":"markdown","metadata":{"id":"ooYn4IUy6D13"},"source":["# 8. YOLO v3 Pre-Trained Weight gdown from Auther's GDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"executionInfo":{"elapsed":3031,"status":"ok","timestamp":1670463092854,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"},"user_tz":-540},"outputId":"20c8b1bd-108a-4e2d-c019-3ef8ed4f6dae","id":"hIYufg-g6D13"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1ZOqdFdqSnHUd9X_TfBGktScjDTeeZ8gc\n","To: /content/Yolo_V3_VOC.pth\n","100%|██████████| 248M/248M [00:01<00:00, 149MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'./checkpoints/Yolo_V3_VOC.pth'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}],"source":["import gdown\n","\n","google_path = 'https://drive.google.com/uc?id='\n","file_id = '1ZOqdFdqSnHUd9X_TfBGktScjDTeeZ8gc'\n","output_name = 'Yolo_V3_VOC.pth'\n","gdown.download(google_path+file_id,output_name,quiet=False)\n","# https://drive.google.com/file/d/1ZOqdFdqSnHUd9X_TfBGktScjDTeeZ8gc/view?usp=sharing\n","\n","shutil.move(\"/content/Yolo_V3_VOC.pth\", \"./checkpoints\")"]},{"cell_type":"markdown","metadata":{"id":"-TLoJBIs6D13"},"source":["# 9. YOLO v3-tiny Pre-Trained Weight gdown from Auther's GDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"executionInfo":{"elapsed":3467,"status":"ok","timestamp":1670463097161,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"},"user_tz":-540},"outputId":"3c1ee914-758b-4644-ee5d-f532bb9eab71","id":"28HC-QR16D13"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1hbz__T-j1Si2o6fGkjhYxRZRsvCTOnCH\n","To: /content/Yolo_V3_VOC_tiny.pth\n","100%|██████████| 35.5M/35.5M [00:01<00:00, 28.4MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'./checkpoints/Yolo_V3_VOC_tiny.pth'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["google_path = 'https://drive.google.com/uc?id='\n","file_id = '1hbz__T-j1Si2o6fGkjhYxRZRsvCTOnCH'\n","output_name = 'Yolo_V3_VOC_tiny.pth'\n","gdown.download(google_path+file_id,output_name,quiet=False)\n","# https://drive.google.com/file/d/1hbz__T-j1Si2o6fGkjhYxRZRsvCTOnCH/view?usp=sharing\n","\n","shutil.move(\"/content/Yolo_V3_VOC_tiny.pth\", \"./checkpoints\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"glAZ5zS46D13"},"outputs":[],"source":["# from google.colab import drive \n","# drive.mount('/content/gdrive/')"]},{"cell_type":"markdown","source":["# 10. Train YOLO v3 from Pre-trained Weights"],"metadata":{"id":"W1L2SRdH6D13"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7820651f-f1f7-4846-bb14-9daa598408f1","id":"aLQoDcdC6D14","executionInfo":{"status":"ok","timestamp":1670465700197,"user_tz":-540,"elapsed":2601645,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["{'data_config': 'config/VOC.data', 'model_def': 'config/yolov3.cfg', 'pretrained_path': 'checkpoints/Yolo_V3_VOC.pth', 'save_path': 'checkpoints/Yolo_V3_VOC.pth', 'working_dir': './', 'num_epochs': 3, 'batch_size': 8, 'img_size': 416, 'n_cpu': 1, 'gradient_accumulations': 2, 'evaluation_interval': 2, 'multiscale_training': True, 'checkpoint_freq': 2, 'iou_thres': 0.5, 'conf_thres': 0.5, 'nms_thres': 0.5, 'ckpt_dir': './checkpoints', 'logs_dir': './logs'}\n","cuda\n","checkpoints/Yolo_V3_VOC.pth\n","Trained pytorch weight loaded!\n","1700\n","  4% 60/1700 [00:41<16:17,  1.68it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 12% 203/1700 [01:50<16:37,  1.50it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 23% 396/1700 [03:25<10:31,  2.06it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 565/1700 [04:50<08:51,  2.14it/s]\n","---- [Epoch 1/3, Batch 566/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 12           | 24           | 48           |\n","| loss       | 1.670039     | 1.765959     | 1.712551     |\n","| loss_x     | 0.035110     | 0.049646     | 0.086125     |\n","| loss_y     | 0.042361     | 0.044394     | 0.052092     |\n","| loss_w     | 0.034108     | 0.031657     | 0.111119     |\n","| loss_h     | 0.020803     | 0.014259     | 0.065093     |\n","| loss_obj   | 1.520888     | 1.612378     | 1.385945     |\n","| loss_cls   | 0.016768     | 0.013626     | 0.012176     |\n","| cls_acc    | 70.37%       | 81.48%       | 85.19%       |\n","| conf_obj   | 0.517698     | 0.588963     | 0.635939     |\n","| conf_noobj | 0.005033     | 0.004778     | 0.004398     |\n","+------------+--------------+--------------+--------------+\n","Total loss 5.148548603057861\n","---- ETA 0:09:43.158752\n"," 59% 1002/1700 [08:22<05:21,  2.17it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 64% 1091/1700 [09:10<05:15,  1.93it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 67% 1131/1700 [09:35<06:41,  1.42it/s]\n","---- [Epoch 1/3, Batch 1132/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 15           | 30           | 60           |\n","| loss       | 1.643564     | 1.074644     | 1.135600     |\n","| loss_x     | 0.014330     | 0.047329     | 0.080405     |\n","| loss_y     | 0.028031     | 0.027080     | 0.066332     |\n","| loss_w     | 0.029155     | 0.058388     | 0.057428     |\n","| loss_h     | 0.009779     | 0.007769     | 0.016374     |\n","| loss_obj   | 1.540637     | 0.911883     | 0.896178     |\n","| loss_cls   | 0.021633     | 0.022195     | 0.018883     |\n","| cls_acc    | 61.90%       | 61.90%       | 71.43%       |\n","| conf_obj   | 0.605830     | 0.730813     | 0.772274     |\n","| conf_noobj | 0.004147     | 0.003500     | 0.003356     |\n","+------------+--------------+--------------+--------------+\n","Total loss 3.8538079261779785\n","---- ETA 0:04:48.880173\n"," 88% 1500/1700 [12:33<00:59,  3.36it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 98% 1667/1700 [13:50<00:14,  2.29it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","100% 1697/1700 [14:08<00:02,  1.49it/s]\n","---- [Epoch 1/3, Batch 1698/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 15           | 30           | 60           |\n","| loss       | 0.923122     | 0.895646     | 0.865220     |\n","| loss_x     | 0.024045     | 0.025305     | 0.070596     |\n","| loss_y     | 0.014806     | 0.050319     | 0.077458     |\n","| loss_w     | 0.018784     | 0.028600     | 0.062631     |\n","| loss_h     | 0.005240     | 0.003752     | 0.003760     |\n","| loss_obj   | 0.844783     | 0.773757     | 0.635304     |\n","| loss_cls   | 0.015465     | 0.013912     | 0.015470     |\n","| cls_acc    | 76.92%       | 76.92%       | 76.92%       |\n","| conf_obj   | 0.754183     | 0.754611     | 0.790304     |\n","| conf_noobj | 0.003069     | 0.002633     | 0.002507     |\n","+------------+--------------+--------------+--------------+\n","Total loss 2.683988571166992\n","---- ETA 0:00:00.999956\n","100% 1700/1700 [14:09<00:00,  2.00it/s]\n","Current epoch loss : 5.17059 Saved at checkpoints/Yolo_V3_VOC.pth\n","1700\n","  1% 15/1700 [00:07<11:01,  2.55it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","  2% 39/1700 [00:17<09:33,  2.90it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","  9% 152/1700 [01:14<12:28,  2.07it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 27% 465/1700 [03:55<08:02,  2.56it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 28% 477/1700 [04:00<10:45,  1.89it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 565/1700 [04:45<08:16,  2.29it/s]\n","---- [Epoch 2/3, Batch 566/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 11           | 22           | 44           |\n","| loss       | 2.093453     | 2.052408     | 1.748138     |\n","| loss_x     | 0.027162     | 0.068295     | 0.049318     |\n","| loss_y     | 0.021541     | 0.020105     | 0.042383     |\n","| loss_w     | 0.063147     | 0.023398     | 0.028245     |\n","| loss_h     | 0.022957     | 0.013006     | 0.001968     |\n","| loss_obj   | 1.933475     | 1.899687     | 1.600968     |\n","| loss_cls   | 0.025171     | 0.027917     | 0.025255     |\n","| cls_acc    | 75.00%       | 66.67%       | 66.67%       |\n","| conf_obj   | 0.497675     | 0.514311     | 0.547210     |\n","| conf_noobj | 0.003854     | 0.003592     | 0.002985     |\n","+------------+--------------+--------------+--------------+\n","Total loss 5.893999099731445\n","---- ETA 0:37:56.469143\n"," 64% 1088/1700 [09:00<05:56,  1.72it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 67% 1131/1700 [09:21<05:47,  1.64it/s]\n","---- [Epoch 2/3, Batch 1132/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 15           | 30           | 60           |\n","| loss       | 1.550709     | 1.331984     | 1.320617     |\n","| loss_x     | 0.068398     | 0.066193     | 0.059252     |\n","| loss_y     | 0.027293     | 0.058808     | 0.078791     |\n","| loss_w     | 0.082350     | 0.016773     | 0.012714     |\n","| loss_h     | 0.015654     | 0.007390     | 0.009691     |\n","| loss_obj   | 1.317100     | 1.158730     | 1.133323     |\n","| loss_cls   | 0.039913     | 0.024090     | 0.026846     |\n","| cls_acc    | 54.55%       | 54.55%       | 45.45%       |\n","| conf_obj   | 0.584087     | 0.642876     | 0.620141     |\n","| conf_noobj | 0.005083     | 0.004391     | 0.003870     |\n","+------------+--------------+--------------+--------------+\n","Total loss 4.203310489654541\n","---- ETA 0:11:49.089599\n"," 91% 1544/1700 [12:41<01:09,  2.26it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","100% 1697/1700 [13:47<00:01,  2.44it/s]\n","---- [Epoch 2/3, Batch 1698/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 11           | 22           | 44           |\n","| loss       | 1.409386     | 1.095754     | 0.882296     |\n","| loss_x     | 0.035896     | 0.036104     | 0.062042     |\n","| loss_y     | 0.024294     | 0.017178     | 0.044195     |\n","| loss_w     | 0.051488     | 0.031799     | 0.037683     |\n","| loss_h     | 0.018269     | 0.018422     | 0.013506     |\n","| loss_obj   | 1.259561     | 0.970076     | 0.706629     |\n","| loss_cls   | 0.019879     | 0.022173     | 0.018240     |\n","| cls_acc    | 61.54%       | 69.23%       | 69.23%       |\n","| conf_obj   | 0.599017     | 0.687764     | 0.784948     |\n","| conf_noobj | 0.004039     | 0.003649     | 0.003129     |\n","+------------+--------------+--------------+--------------+\n","Total loss 3.3874356746673584\n","---- ETA 0:00:01.976941\n","100% 1700/1700 [13:48<00:00,  2.05it/s]\n","Current epoch loss : 5.28272 Saved at checkpoints/Yolo_V3_VOC.pth\n","1700\n","  4% 72/1700 [00:35<13:00,  2.09it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 14% 246/1700 [01:55<14:10,  1.71it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 565/1700 [04:32<13:30,  1.40it/s]\n","---- [Epoch 3/3, Batch 566/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 16           | 32           | 64           |\n","| loss       | 1.918595     | 1.633014     | 1.450290     |\n","| loss_x     | 0.041884     | 0.052683     | 0.071793     |\n","| loss_y     | 0.024175     | 0.053142     | 0.068922     |\n","| loss_w     | 0.028647     | 0.022684     | 0.020314     |\n","| loss_h     | 0.017645     | 0.025734     | 0.024792     |\n","| loss_obj   | 1.774950     | 1.451424     | 1.238336     |\n","| loss_cls   | 0.031294     | 0.027347     | 0.026132     |\n","| cls_acc    | 41.67%       | 50.00%       | 58.33%       |\n","| conf_obj   | 0.444802     | 0.530863     | 0.619807     |\n","| conf_noobj | 0.004417     | 0.003737     | 0.003701     |\n","+------------+--------------+--------------+--------------+\n","Total loss 5.001899719238281\n","---- ETA 1:05:12.063141\n"," 35% 589/1700 [04:44<06:31,  2.84it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 41% 705/1700 [05:37<07:16,  2.28it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 49% 832/1700 [06:35<04:14,  3.41it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 63% 1078/1700 [08:32<03:50,  2.70it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 67% 1131/1700 [09:02<05:49,  1.63it/s]\n","---- [Epoch 3/3, Batch 1132/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 15           | 30           | 60           |\n","| loss       | 2.767683     | 2.740996     | 2.422724     |\n","| loss_x     | 0.036514     | 0.043745     | 0.061054     |\n","| loss_y     | 0.051231     | 0.052807     | 0.070691     |\n","| loss_w     | 0.090340     | 0.055163     | 0.052510     |\n","| loss_h     | 0.060135     | 0.059093     | 0.060421     |\n","| loss_obj   | 2.507170     | 2.504413     | 2.155331     |\n","| loss_cls   | 0.022294     | 0.025774     | 0.022716     |\n","| cls_acc    | 72.22%       | 50.00%       | 61.11%       |\n","| conf_obj   | 0.434022     | 0.468548     | 0.516268     |\n","| conf_noobj | 0.004720     | 0.003756     | 0.003451     |\n","+------------+--------------+--------------+--------------+\n","Total loss 7.931402206420898\n","---- ETA 0:18:35.283653\n"," 94% 1605/1700 [12:52<00:41,  2.27it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","100% 1697/1700 [13:44<00:01,  1.80it/s]\n","---- [Epoch 3/3, Batch 1698/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 13           | 26           | 52           |\n","| loss       | 2.218550     | 2.240453     | 2.136717     |\n","| loss_x     | 0.043643     | 0.064195     | 0.076067     |\n","| loss_y     | 0.020883     | 0.035292     | 0.087979     |\n","| loss_w     | 0.072473     | 0.020769     | 0.041427     |\n","| loss_h     | 0.053980     | 0.035992     | 0.082275     |\n","| loss_obj   | 1.995208     | 2.054048     | 1.819267     |\n","| loss_cls   | 0.032364     | 0.030158     | 0.029703     |\n","| cls_acc    | 45.00%       | 47.62%       | 47.62%       |\n","| conf_obj   | 0.485738     | 0.554706     | 0.574685     |\n","| conf_noobj | 0.005242     | 0.004522     | 0.003961     |\n","+------------+--------------+--------------+--------------+\n","Total loss 6.595720291137695\n","---- ETA 0:00:02.949862\n","100% 1700/1700 [13:45<00:00,  2.06it/s]\n","Current epoch loss : 5.23649 Saved at checkpoints/Yolo_V3_VOC.pth\n","\n","---- Evaluating Model ----\n","Detecting objects:  90% 382/425 [01:11<00:08,  5.32it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005953.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","Detecting objects: 100% 425/425 [01:19<00:00,  5.33it/s]\n","Computing AP: 100% 20/20 [00:00<00:00, 491.07it/s]\n","+-------+-------------+---------+\n","| Index | Class name  | AP      |\n","+-------+-------------+---------+\n","| 0     | aeroplane   | 0.33660 |\n","| 1     | bicycle     | 0.15676 |\n","| 2     | bird        | 0.03956 |\n","| 3     | boat        | 0.06313 |\n","| 4     | bottle      | 0.20189 |\n","| 5     | bus         | 0.22185 |\n","| 6     | car         | 0.26507 |\n","| 7     | cat         | 0.31624 |\n","| 8     | chair       | 0.25326 |\n","| 9     | cow         | 0.00354 |\n","| 10    | diningtable | 0.18809 |\n","| 11    | dog         | 0.15474 |\n","| 12    | horse       | 0.01884 |\n","| 13    | motorbike   | 0.11609 |\n","| 14    | person      | 0.77517 |\n","| 15    | pottedplant | 0.16300 |\n","| 16    | sheep       | 0.17475 |\n","| 17    | sofa        | 0.06623 |\n","| 18    | train       | 0.21600 |\n","| 19    | tvmonitor   | 0.29012 |\n","+-------+-------------+---------+\n","---- mAP 0.20104568714952178\n"]}],"source":["! python train.py --num_epochs 3 --batch_size 8 --data_config config/VOC.data --model_def config/yolov3.cfg --pretrained_path checkpoints/Yolo_V3_VOC.pth --save_path checkpoints/Yolo_V3_VOC.pth"]},{"cell_type":"markdown","source":["# 11. Train YOLO v3 from Darknet Weights"],"metadata":{"id":"KWDHIzd36D14"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hj8VyyjF6D14","executionInfo":{"status":"ok","timestamp":1670468264794,"user_tz":-540,"elapsed":2564601,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"876167d1-b69b-458e-b219-30364be7b6e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'data_config': 'config/VOC.data', 'model_def': 'config/yolov3.cfg', 'pretrained_path': 'checkpoints/yolov3.weights', 'save_path': 'checkpoints/Yolo_V3_VOC.pth', 'working_dir': './', 'num_epochs': 3, 'batch_size': 8, 'img_size': 416, 'n_cpu': 1, 'gradient_accumulations': 2, 'evaluation_interval': 2, 'multiscale_training': True, 'checkpoint_freq': 2, 'iou_thres': 0.5, 'conf_thres': 0.5, 'nms_thres': 0.5, 'ckpt_dir': './checkpoints', 'logs_dir': './logs'}\n","cuda\n","checkpoints/yolov3.weights\n","Darknet weight loaded!\n","1700\n"," 17% 287/1700 [02:10<16:21,  1.44it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 565/1700 [04:30<08:40,  2.18it/s]\n","---- [Epoch 1/3, Batch 566/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 11           | 22           | 44           |\n","| loss       | 2.782181     | 2.104304     | 2.067480     |\n","| loss_x     | 0.122841     | 0.082843     | 0.059691     |\n","| loss_y     | 0.052602     | 0.037796     | 0.102489     |\n","| loss_w     | 0.054501     | 0.098577     | 0.092740     |\n","| loss_h     | 0.044852     | 0.060138     | 0.040182     |\n","| loss_obj   | 2.473835     | 1.791126     | 1.740464     |\n","| loss_cls   | 0.033550     | 0.033824     | 0.031913     |\n","| cls_acc    | 58.33%       | 58.33%       | 58.33%       |\n","| conf_obj   | 0.296292     | 0.433700     | 0.440214     |\n","| conf_noobj | 0.006761     | 0.006480     | 0.006381     |\n","+------------+--------------+--------------+--------------+\n","Total loss 6.953965187072754\n","---- ETA 0:09:01.900645\n"," 51% 859/1700 [07:00<09:25,  1.49it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 57% 977/1700 [07:54<05:13,  2.31it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 59% 1004/1700 [08:07<06:30,  1.78it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 67% 1131/1700 [09:07<03:14,  2.93it/s]\n","---- [Epoch 1/3, Batch 1132/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 10           | 20           | 40           |\n","| loss       | 3.232458     | 2.532078     | 2.718899     |\n","| loss_x     | 0.088404     | 0.051422     | 0.037968     |\n","| loss_y     | 0.083960     | 0.077845     | 0.089320     |\n","| loss_w     | 0.386001     | 0.099794     | 0.231960     |\n","| loss_h     | 0.102739     | 0.050447     | 0.045070     |\n","| loss_obj   | 2.538119     | 2.220743     | 2.283839     |\n","| loss_cls   | 0.033235     | 0.031827     | 0.030741     |\n","| cls_acc    | 64.00%       | 61.54%       | 65.38%       |\n","| conf_obj   | 0.233105     | 0.346284     | 0.325476     |\n","| conf_noobj | 0.005929     | 0.006418     | 0.006296     |\n","+------------+--------------+--------------+--------------+\n","Total loss 8.483434677124023\n","---- ETA 0:04:34.842865\n"," 75% 1267/1700 [10:16<04:48,  1.50it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 78% 1318/1700 [10:38<02:11,  2.91it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 87% 1473/1700 [11:53<02:15,  1.68it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","100% 1697/1700 [13:45<00:02,  1.44it/s]\n","---- [Epoch 1/3, Batch 1698/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 16           | 32           | 64           |\n","| loss       | 3.715726     | 3.345648     | 3.435171     |\n","| loss_x     | 0.074899     | 0.046207     | 0.067756     |\n","| loss_y     | 0.057879     | 0.084830     | 0.097174     |\n","| loss_w     | 0.186093     | 0.127975     | 0.175672     |\n","| loss_h     | 0.139315     | 0.053516     | 0.159408     |\n","| loss_obj   | 3.218442     | 2.993070     | 2.895075     |\n","| loss_cls   | 0.039096     | 0.040050     | 0.040086     |\n","| cls_acc    | 36.36%       | 35.29%       | 38.24%       |\n","| conf_obj   | 0.210730     | 0.266473     | 0.288304     |\n","| conf_noobj | 0.007696     | 0.006717     | 0.006502     |\n","+------------+--------------+--------------+--------------+\n","Total loss 10.49654483795166\n","---- ETA 0:00:00.972778\n","100% 1700/1700 [13:46<00:00,  2.06it/s]\n","Current epoch loss : 9.28621 Saved at checkpoints/Yolo_V3_VOC.pth\n","1700\n"," 12% 196/1700 [01:32<08:14,  3.04it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 18% 314/1700 [02:22<12:17,  1.88it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 565/1700 [04:35<12:45,  1.48it/s]\n","---- [Epoch 2/3, Batch 566/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 15           | 30           | 60           |\n","| loss       | 2.979619     | 2.796088     | 2.687424     |\n","| loss_x     | 0.073571     | 0.091931     | 0.101705     |\n","| loss_y     | 0.064245     | 0.080632     | 0.062393     |\n","| loss_w     | 0.062674     | 0.033130     | 0.049510     |\n","| loss_h     | 0.026038     | 0.059485     | 0.059027     |\n","| loss_obj   | 2.708594     | 2.480830     | 2.365817     |\n","| loss_cls   | 0.044496     | 0.050081     | 0.048973     |\n","| cls_acc    | 26.67%       | 26.67%       | 20.00%       |\n","| conf_obj   | 0.252177     | 0.295549     | 0.344675     |\n","| conf_noobj | 0.008303     | 0.007262     | 0.007281     |\n","+------------+--------------+--------------+--------------+\n","Total loss 8.46313190460205\n","---- ETA 0:36:51.170586\n"," 50% 847/1700 [06:51<07:27,  1.91it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 63% 1076/1700 [08:46<05:01,  2.07it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 65% 1102/1700 [08:57<04:24,  2.26it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 67% 1131/1700 [09:14<05:18,  1.78it/s]\n","---- [Epoch 2/3, Batch 1132/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 14           | 28           | 56           |\n","| loss       | 3.267069     | 2.950805     | 2.990306     |\n","| loss_x     | 0.103401     | 0.070093     | 0.054254     |\n","| loss_y     | 0.081879     | 0.070369     | 0.067287     |\n","| loss_w     | 0.080037     | 0.091010     | 0.175092     |\n","| loss_h     | 0.103088     | 0.058771     | 0.245988     |\n","| loss_obj   | 2.852939     | 2.610973     | 2.402179     |\n","| loss_cls   | 0.045726     | 0.049588     | 0.045506     |\n","| cls_acc    | 40.91%       | 39.13%       | 39.13%       |\n","| conf_obj   | 0.319147     | 0.352949     | 0.347515     |\n","| conf_noobj | 0.007503     | 0.006777     | 0.006742     |\n","+------------+--------------+--------------+--------------+\n","Total loss 9.208179473876953\n","---- ETA 0:11:33.825440\n"," 85% 1445/1700 [11:44<02:19,  1.83it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 98% 1660/1700 [13:31<00:19,  2.05it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","100% 1697/1700 [13:51<00:01,  2.19it/s]\n","---- [Epoch 2/3, Batch 1698/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 12           | 24           | 48           |\n","| loss       | 2.783116     | 2.173173     | 2.385156     |\n","| loss_x     | 0.083345     | 0.065392     | 0.055836     |\n","| loss_y     | 0.075860     | 0.024906     | 0.069158     |\n","| loss_w     | 0.277946     | 0.120829     | 0.096473     |\n","| loss_h     | 0.067618     | 0.073823     | 0.112619     |\n","| loss_obj   | 2.235172     | 1.854475     | 2.008888     |\n","| loss_cls   | 0.043175     | 0.033749     | 0.042181     |\n","| cls_acc    | 41.67%       | 53.33%       | 42.86%       |\n","| conf_obj   | 0.419770     | 0.498438     | 0.454228     |\n","| conf_noobj | 0.006748     | 0.006714     | 0.006296     |\n","+------------+--------------+--------------+--------------+\n","Total loss 7.341445446014404\n","---- ETA 0:00:01.955027\n","100% 1700/1700 [13:52<00:00,  2.04it/s]\n","Current epoch loss : 8.67381 Saved at checkpoints/Yolo_V3_VOC.pth\n","1700\n"," 33% 565/1700 [04:18<08:52,  2.13it/s]\n","---- [Epoch 3/3, Batch 566/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 12           | 24           | 48           |\n","| loss       | 3.846099     | 3.013017     | 2.690630     |\n","| loss_x     | 0.084463     | 0.082812     | 0.097554     |\n","| loss_y     | 0.076700     | 0.084740     | 0.055239     |\n","| loss_w     | 0.103527     | 0.249935     | 0.280799     |\n","| loss_h     | 0.066802     | 0.045513     | 0.102537     |\n","| loss_obj   | 3.468607     | 2.500754     | 2.110159     |\n","| loss_cls   | 0.046000     | 0.049263     | 0.044342     |\n","| cls_acc    | 26.67%       | 20.00%       | 26.67%       |\n","| conf_obj   | 0.197285     | 0.276864     | 0.355291     |\n","| conf_noobj | 0.008058     | 0.006891     | 0.006611     |\n","+------------+--------------+--------------+--------------+\n","Total loss 9.549745559692383\n","---- ETA 1:04:06.737882\n"," 53% 906/1700 [06:58<06:20,  2.09it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 65% 1112/1700 [08:42<04:26,  2.20it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 67% 1131/1700 [08:50<03:51,  2.46it/s]\n","---- [Epoch 3/3, Batch 1132/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 11           | 22           | 44           |\n","| loss       | 2.417366     | 1.931659     | 1.986707     |\n","| loss_x     | 0.049899     | 0.068597     | 0.093241     |\n","| loss_y     | 0.016860     | 0.063044     | 0.080238     |\n","| loss_w     | 0.068695     | 0.025080     | 0.066532     |\n","| loss_h     | 0.027221     | 0.061341     | 0.079668     |\n","| loss_obj   | 2.204025     | 1.656846     | 1.608736     |\n","| loss_cls   | 0.050666     | 0.056751     | 0.058293     |\n","| cls_acc    | 20.00%       | 20.00%       | 20.00%       |\n","| conf_obj   | 0.361604     | 0.499353     | 0.504538     |\n","| conf_noobj | 0.006791     | 0.006608     | 0.006582     |\n","+------------+--------------+--------------+--------------+\n","Total loss 6.335732460021973\n","---- ETA 0:18:19.827783\n"," 73% 1248/1700 [09:54<04:30,  1.67it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 76% 1298/1700 [10:18<02:17,  2.93it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 88% 1504/1700 [11:57<01:19,  2.47it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 89% 1505/1700 [11:58<01:29,  2.17it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 95% 1615/1700 [12:55<00:54,  1.57it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","100% 1697/1700 [13:34<00:01,  1.73it/s]\n","---- [Epoch 3/3, Batch 1698/1700] ----\n","+------------+--------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |\n","+------------+--------------+--------------+--------------+\n","| grid_size  | 14           | 28           | 56           |\n","| loss       | 3.645267     | 3.164606     | 3.190814     |\n","| loss_x     | 0.072897     | 0.077707     | 0.070864     |\n","| loss_y     | 0.058000     | 0.079615     | 0.089336     |\n","| loss_w     | 0.204718     | 0.131477     | 0.143966     |\n","| loss_h     | 0.068446     | 0.021170     | 0.027685     |\n","| loss_obj   | 3.207445     | 2.823022     | 2.830940     |\n","| loss_cls   | 0.033761     | 0.031616     | 0.028024     |\n","| cls_acc    | 57.89%       | 57.89%       | 63.16%       |\n","| conf_obj   | 0.173577     | 0.189657     | 0.192442     |\n","| conf_noobj | 0.007230     | 0.006679     | 0.006609     |\n","+------------+--------------+--------------+--------------+\n","Total loss 10.000688552856445\n","---- ETA 0:00:02.916898\n","100% 1700/1700 [13:36<00:00,  2.08it/s]\n","Current epoch loss : 8.67856 Saved at checkpoints/Yolo_V3_VOC.pth\n","\n","---- Evaluating Model ----\n","Detecting objects:  90% 382/425 [01:09<00:07,  5.41it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005953.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","Detecting objects: 100% 425/425 [01:17<00:00,  5.47it/s]\n","Computing AP: 100% 20/20 [00:00<00:00, 703.03it/s]\n","+-------+-------------+---------+\n","| Index | Class name  | AP      |\n","+-------+-------------+---------+\n","| 0     | aeroplane   | 0.00007 |\n","| 1     | bicycle     | 0.00000 |\n","| 2     | bird        | 0.00007 |\n","| 3     | boat        | 0.00122 |\n","| 4     | bottle      | 0.00000 |\n","| 5     | bus         | 0.00000 |\n","| 6     | car         | 0.05733 |\n","| 7     | cat         | 0.00000 |\n","| 8     | chair       | 0.00105 |\n","| 9     | cow         | 0.00000 |\n","| 10    | diningtable | 0.00000 |\n","| 11    | dog         | 0.00000 |\n","| 12    | horse       | 0.00000 |\n","| 13    | motorbike   | 0.00000 |\n","| 14    | person      | 0.36727 |\n","| 15    | pottedplant | 0.00000 |\n","| 16    | sheep       | 0.04690 |\n","| 17    | sofa        | 0.00000 |\n","| 18    | train       | 0.00000 |\n","| 19    | tvmonitor   | 0.00000 |\n","+-------+-------------+---------+\n","---- mAP 0.023696024683223967\n"]}],"source":["! python train.py --num_epochs 3 --batch_size 8 --data_config config/VOC.data --model_def config/yolov3.cfg --pretrained_path checkpoints/yolov3.weights --save_path checkpoints/Yolo_V3_VOC.pth"]},{"cell_type":"markdown","source":["# 12. Train YOLO v3-tiny from Pre-trained Weights"],"metadata":{"id":"CsqpVhtk6D14"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nVOv491-6D14","executionInfo":{"status":"ok","timestamp":1670468684297,"user_tz":-540,"elapsed":419506,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"e0e4800f-0b40-4935-d86b-3e0a6b69f572"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'data_config': 'config/VOC.data', 'model_def': 'config/yolov3-tiny.cfg', 'pretrained_path': 'checkpoints/Yolo_V3_VOC_tiny.pth', 'save_path': 'checkpoints/Yolo_V3_VOC_tiny.pth', 'working_dir': './', 'num_epochs': 3, 'batch_size': 32, 'img_size': 416, 'n_cpu': 1, 'gradient_accumulations': 2, 'evaluation_interval': 2, 'multiscale_training': True, 'checkpoint_freq': 2, 'iou_thres': 0.5, 'conf_thres': 0.5, 'nms_thres': 0.5, 'ckpt_dir': './checkpoints', 'logs_dir': './logs'}\n","cuda\n","checkpoints/Yolo_V3_VOC_tiny.pth\n","Trained pytorch weight loaded!\n","425\n","  9% 37/425 [00:12<01:54,  3.40it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 140/425 [00:43<01:16,  3.71it/s]\n","---- [Epoch 1/3, Batch 141/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 13           | 26           |\n","| loss       | 2.032367     | 2.130724     |\n","| loss_x     | 0.055756     | 0.069051     |\n","| loss_y     | 0.044938     | 0.081731     |\n","| loss_w     | 0.065763     | 0.037436     |\n","| loss_h     | 0.032082     | 0.032915     |\n","| loss_obj   | 1.822036     | 1.895436     |\n","| loss_cls   | 0.011791     | 0.014156     |\n","| cls_acc    | 81.82%       | 77.92%       |\n","| conf_obj   | 0.471265     | 0.447632     |\n","| conf_noobj | 0.006296     | 0.006302     |\n","+------------+--------------+--------------+\n","Total loss 4.16309118270874\n","---- ETA 0:01:29.124785\n"," 46% 194/425 [00:59<01:11,  3.23it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 59% 250/425 [01:16<00:55,  3.15it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 66% 281/425 [01:25<00:42,  3.37it/s]\n","---- [Epoch 1/3, Batch 282/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 12           | 24           |\n","| loss       | 2.377505     | 2.449927     |\n","| loss_x     | 0.049079     | 0.073605     |\n","| loss_y     | 0.063690     | 0.081862     |\n","| loss_w     | 0.067442     | 0.040074     |\n","| loss_h     | 0.082801     | 0.043212     |\n","| loss_obj   | 2.099606     | 2.194435     |\n","| loss_cls   | 0.014886     | 0.016740     |\n","| cls_acc    | 78.46%       | 72.31%       |\n","| conf_obj   | 0.411468     | 0.383253     |\n","| conf_noobj | 0.005969     | 0.005973     |\n","+------------+--------------+--------------+\n","Total loss 4.827432632446289\n","---- ETA 0:00:43.403637\n"," 72% 307/425 [01:32<00:33,  3.52it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 77% 327/425 [01:38<00:28,  3.38it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 89% 379/425 [01:55<00:13,  3.35it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 94% 400/425 [02:01<00:07,  3.38it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 99% 422/425 [02:07<00:00,  3.40it/s]\n","---- [Epoch 1/3, Batch 423/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 13           | 26           |\n","| loss       | 1.897169     | 1.910504     |\n","| loss_x     | 0.059624     | 0.068007     |\n","| loss_y     | 0.042108     | 0.059945     |\n","| loss_w     | 0.065502     | 0.035492     |\n","| loss_h     | 0.037554     | 0.017057     |\n","| loss_obj   | 1.679856     | 1.717181     |\n","| loss_cls   | 0.012525     | 0.012823     |\n","| cls_acc    | 77.42%       | 84.38%       |\n","| conf_obj   | 0.520571     | 0.517361     |\n","| conf_noobj | 0.005792     | 0.005744     |\n","+------------+--------------+--------------+\n","Total loss 3.8076729774475098\n","---- ETA 0:00:00.606990\n","100% 425/425 [02:08<00:00,  3.30it/s]\n","Current epoch loss : 4.63022 Saved at checkpoints/Yolo_V3_VOC_tiny.pth\n","425\n"," 13% 57/425 [00:17<01:49,  3.35it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 140/425 [00:41<01:22,  3.44it/s]\n","---- [Epoch 2/3, Batch 141/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 14           | 28           |\n","| loss       | 1.988175     | 1.930599     |\n","| loss_x     | 0.045869     | 0.086928     |\n","| loss_y     | 0.071583     | 0.078985     |\n","| loss_w     | 0.057912     | 0.038418     |\n","| loss_h     | 0.025681     | 0.035048     |\n","| loss_obj   | 1.771646     | 1.673135     |\n","| loss_cls   | 0.015485     | 0.018086     |\n","| cls_acc    | 76.19%       | 76.19%       |\n","| conf_obj   | 0.482351     | 0.485995     |\n","| conf_noobj | 0.006558     | 0.006080     |\n","+------------+--------------+--------------+\n","Total loss 3.9187746047973633\n","---- ETA 0:05:45.281719\n"," 40% 170/425 [00:50<01:10,  3.61it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 55% 234/425 [01:09<00:52,  3.62it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 56% 238/425 [01:10<00:53,  3.51it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 56% 240/425 [01:11<00:52,  3.50it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 64% 272/425 [01:20<00:48,  3.18it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 66% 281/425 [01:23<00:46,  3.13it/s]\n","---- [Epoch 2/3, Batch 282/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 16           | 32           |\n","| loss       | 2.368784     | 2.214571     |\n","| loss_x     | 0.069612     | 0.087970     |\n","| loss_y     | 0.059554     | 0.072719     |\n","| loss_w     | 0.034515     | 0.062174     |\n","| loss_h     | 0.023447     | 0.038175     |\n","| loss_obj   | 2.166165     | 1.935250     |\n","| loss_cls   | 0.015492     | 0.018283     |\n","| cls_acc    | 74.29%       | 74.65%       |\n","| conf_obj   | 0.386982     | 0.438243     |\n","| conf_noobj | 0.006329     | 0.005756     |\n","+------------+--------------+--------------+\n","Total loss 4.583354949951172\n","---- ETA 0:01:47.854313\n"," 82% 349/425 [01:44<00:23,  3.19it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 99% 422/425 [02:05<00:00,  3.31it/s]\n","---- [Epoch 2/3, Batch 423/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 14           | 28           |\n","| loss       | 2.375739     | 2.079571     |\n","| loss_x     | 0.052714     | 0.084419     |\n","| loss_y     | 0.040729     | 0.075293     |\n","| loss_w     | 0.031741     | 0.058022     |\n","| loss_h     | 0.020318     | 0.047091     |\n","| loss_obj   | 2.214048     | 1.794558     |\n","| loss_cls   | 0.016188     | 0.020188     |\n","| cls_acc    | 72.00%       | 64.00%       |\n","| conf_obj   | 0.367737     | 0.423259     |\n","| conf_noobj | 0.005403     | 0.005327     |\n","+------------+--------------+--------------+\n","Total loss 4.455309867858887\n","---- ETA 0:00:01.203354\n","100% 425/425 [02:06<00:00,  3.37it/s]\n","Current epoch loss : 4.36099 Saved at checkpoints/Yolo_V3_VOC_tiny.pth\n","425\n"," 23% 96/425 [00:28<01:41,  3.23it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 140/425 [00:41<01:27,  3.26it/s]\n","---- [Epoch 3/3, Batch 141/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 11           | 22           |\n","| loss       | 2.490557     | 2.387504     |\n","| loss_x     | 0.041703     | 0.088176     |\n","| loss_y     | 0.043648     | 0.064797     |\n","| loss_w     | 0.102139     | 0.056405     |\n","| loss_h     | 0.042023     | 0.031141     |\n","| loss_obj   | 2.244753     | 2.127746     |\n","| loss_cls   | 0.016290     | 0.019239     |\n","| cls_acc    | 70.59%       | 72.55%       |\n","| conf_obj   | 0.401810     | 0.447016     |\n","| conf_noobj | 0.005986     | 0.005288     |\n","+------------+--------------+--------------+\n","Total loss 4.878061771392822\n","---- ETA 0:09:58.969966\n"," 55% 234/425 [01:09<00:55,  3.41it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 66% 281/425 [01:23<00:40,  3.54it/s]\n","---- [Epoch 3/3, Batch 282/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 10           | 20           |\n","| loss       | 2.222617     | 2.066046     |\n","| loss_x     | 0.059524     | 0.063172     |\n","| loss_y     | 0.029194     | 0.055792     |\n","| loss_w     | 0.119299     | 0.048508     |\n","| loss_h     | 0.074271     | 0.043966     |\n","| loss_obj   | 1.922019     | 1.834245     |\n","| loss_cls   | 0.018310     | 0.020363     |\n","| cls_acc    | 74.58%       | 75.38%       |\n","| conf_obj   | 0.398724     | 0.441919     |\n","| conf_noobj | 0.005803     | 0.005007     |\n","+------------+--------------+--------------+\n","Total loss 4.288662910461426\n","---- ETA 0:02:52.092668\n"," 68% 287/425 [01:25<00:37,  3.71it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 69% 295/425 [01:27<00:37,  3.43it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 71% 303/425 [01:30<00:40,  3.04it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 88% 376/425 [01:51<00:13,  3.70it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 93% 396/425 [01:57<00:08,  3.41it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 99% 422/425 [02:04<00:00,  3.43it/s]\n","---- [Epoch 3/3, Batch 423/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 12           | 24           |\n","| loss       | 2.553659     | 2.370404     |\n","| loss_x     | 0.049877     | 0.072193     |\n","| loss_y     | 0.052495     | 0.076515     |\n","| loss_w     | 0.080374     | 0.044388     |\n","| loss_h     | 0.082045     | 0.058171     |\n","| loss_obj   | 2.275521     | 2.109021     |\n","| loss_cls   | 0.013347     | 0.010116     |\n","| cls_acc    | 77.46%       | 87.67%       |\n","| conf_obj   | 0.378749     | 0.447817     |\n","| conf_noobj | 0.005838     | 0.005539     |\n","+------------+--------------+--------------+\n","Total loss 4.924063682556152\n","---- ETA 0:00:01.798760\n","100% 425/425 [02:05<00:00,  3.38it/s]\n","Current epoch loss : 4.33441 Saved at checkpoints/Yolo_V3_VOC_tiny.pth\n","\n","---- Evaluating Model ----\n","Detecting objects:  89% 95/107 [00:26<00:03,  3.65it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005953.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","Detecting objects: 100% 107/107 [00:29<00:00,  3.60it/s]\n","Computing AP: 100% 20/20 [00:00<00:00, 764.80it/s]\n","+-------+-------------+---------+\n","| Index | Class name  | AP      |\n","+-------+-------------+---------+\n","| 0     | aeroplane   | 0.40792 |\n","| 1     | bicycle     | 0.31741 |\n","| 2     | bird        | 0.27737 |\n","| 3     | boat        | 0.20104 |\n","| 4     | bottle      | 0.27475 |\n","| 5     | bus         | 0.51814 |\n","| 6     | car         | 0.39223 |\n","| 7     | cat         | 0.38874 |\n","| 8     | chair       | 0.37388 |\n","| 9     | cow         | 0.14760 |\n","| 10    | diningtable | 0.23676 |\n","| 11    | dog         | 0.29943 |\n","| 12    | horse       | 0.23764 |\n","| 13    | motorbike   | 0.31103 |\n","| 14    | person      | 0.59391 |\n","| 15    | pottedplant | 0.24283 |\n","| 16    | sheep       | 0.27201 |\n","| 17    | sofa        | 0.19248 |\n","| 18    | train       | 0.41808 |\n","| 19    | tvmonitor   | 0.52976 |\n","+-------+-------------+---------+\n","---- mAP 0.33164953530976093\n"]}],"source":["! python train.py --num_epochs 3 --batch_size 32 --data_config config/VOC.data --model_def config/yolov3-tiny.cfg --pretrained_path checkpoints/Yolo_V3_VOC_tiny.pth --save_path checkpoints/Yolo_V3_VOC_tiny.pth"]},{"cell_type":"markdown","source":["# 13. Train YOLO v3-tiny from Darknet Weights"],"metadata":{"id":"l2tIbHyk6D14"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfSv7q006D14","executionInfo":{"status":"ok","timestamp":1670469719465,"user_tz":-540,"elapsed":1035179,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"60f89bea-680d-4f53-b562-cb7e0d659f2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'data_config': 'config/VOC.data', 'model_def': 'config/yolov3-tiny.cfg', 'pretrained_path': 'checkpoints/yolov3-tiny.weights', 'save_path': 'checkpoints/Yolo_V3_VOC_tiny.pth', 'working_dir': './', 'num_epochs': 8, 'batch_size': 32, 'img_size': 416, 'n_cpu': 1, 'gradient_accumulations': 2, 'evaluation_interval': 2, 'multiscale_training': True, 'checkpoint_freq': 2, 'iou_thres': 0.5, 'conf_thres': 0.5, 'nms_thres': 0.5, 'ckpt_dir': './checkpoints', 'logs_dir': './logs'}\n","cuda\n","checkpoints/yolov3-tiny.weights\n","Darknet weight loaded!\n","425\n"," 33% 140/425 [00:42<01:23,  3.43it/s]\n","---- [Epoch 1/8, Batch 141/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 12           | 24           |\n","| loss       | 2.895460     | 2.995627     |\n","| loss_x     | 0.067940     | 0.063433     |\n","| loss_y     | 0.039197     | 0.082050     |\n","| loss_w     | 0.157502     | 0.093578     |\n","| loss_h     | 0.096394     | 0.059707     |\n","| loss_obj   | 2.513033     | 2.669849     |\n","| loss_cls   | 0.021395     | 0.027010     |\n","| cls_acc    | 70.83%       | 66.23%       |\n","| conf_obj   | 0.367379     | 0.346589     |\n","| conf_noobj | 0.006491     | 0.006841     |\n","+------------+--------------+--------------+\n","Total loss 5.891087055206299\n","---- ETA 0:01:26.764834\n"," 35% 149/425 [00:45<01:23,  3.32it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 38% 163/425 [00:49<01:29,  2.92it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 49% 210/425 [01:03<01:04,  3.35it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 66% 281/425 [01:25<00:42,  3.40it/s]\n","---- [Epoch 1/8, Batch 282/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 14           | 28           |\n","| loss       | 2.246373     | 2.237122     |\n","| loss_x     | 0.075484     | 0.086269     |\n","| loss_y     | 0.051280     | 0.084213     |\n","| loss_w     | 0.041136     | 0.055218     |\n","| loss_h     | 0.044546     | 0.051723     |\n","| loss_obj   | 2.002086     | 1.919393     |\n","| loss_cls   | 0.031840     | 0.040306     |\n","| cls_acc    | 48.00%       | 37.25%       |\n","| conf_obj   | 0.424097     | 0.451484     |\n","| conf_noobj | 0.006232     | 0.007064     |\n","+------------+--------------+--------------+\n","Total loss 4.483494758605957\n","---- ETA 0:00:43.552696\n"," 70% 296/425 [01:29<00:37,  3.44it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 71% 303/425 [01:32<00:40,  2.98it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 77% 326/425 [01:38<00:30,  3.26it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 90% 381/425 [01:55<00:14,  3.08it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 99% 422/425 [02:07<00:00,  3.47it/s]\n","---- [Epoch 1/8, Batch 423/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 13           | 26           |\n","| loss       | 2.912210     | 2.668722     |\n","| loss_x     | 0.050431     | 0.071994     |\n","| loss_y     | 0.041601     | 0.072862     |\n","| loss_w     | 0.130680     | 0.061470     |\n","| loss_h     | 0.100981     | 0.057520     |\n","| loss_obj   | 2.561340     | 2.372191     |\n","| loss_cls   | 0.027177     | 0.032685     |\n","| cls_acc    | 59.09%       | 50.00%       |\n","| conf_obj   | 0.340320     | 0.347717     |\n","| conf_noobj | 0.006073     | 0.006590     |\n","+------------+--------------+--------------+\n","Total loss 5.5809326171875\n","---- ETA 0:00:00.605151\n","100% 425/425 [02:08<00:00,  3.31it/s]\n","Current epoch loss : 5.75983 Saved at checkpoints/Yolo_V3_VOC_tiny.pth\n","425\n"," 23% 97/425 [00:29<01:32,  3.54it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 26% 110/425 [00:32<01:34,  3.33it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 29% 124/425 [00:37<01:27,  3.43it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 140/425 [00:41<01:19,  3.59it/s]\n","---- [Epoch 2/8, Batch 141/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 15           | 30           |\n","| loss       | 2.691361     | 2.631090     |\n","| loss_x     | 0.054905     | 0.079658     |\n","| loss_y     | 0.051849     | 0.083645     |\n","| loss_w     | 0.050729     | 0.079513     |\n","| loss_h     | 0.034120     | 0.045603     |\n","| loss_obj   | 2.477782     | 2.310003     |\n","| loss_cls   | 0.021976     | 0.032669     |\n","| cls_acc    | 68.75%       | 51.56%       |\n","| conf_obj   | 0.297064     | 0.322140     |\n","| conf_noobj | 0.006332     | 0.006072     |\n","+------------+--------------+--------------+\n","Total loss 5.322450637817383\n","---- ETA 0:05:43.950458\n"," 37% 156/425 [00:46<01:19,  3.40it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 46% 195/425 [00:58<01:08,  3.34it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 52% 220/425 [01:05<01:05,  3.13it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 66% 281/425 [01:24<00:40,  3.53it/s]\n","---- [Epoch 2/8, Batch 282/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 10           | 20           |\n","| loss       | 2.964533     | 2.831290     |\n","| loss_x     | 0.064470     | 0.071169     |\n","| loss_y     | 0.052409     | 0.075851     |\n","| loss_w     | 0.176760     | 0.105547     |\n","| loss_h     | 0.052543     | 0.083182     |\n","| loss_obj   | 2.589598     | 2.461240     |\n","| loss_cls   | 0.028753     | 0.034302     |\n","| cls_acc    | 49.06%       | 47.17%       |\n","| conf_obj   | 0.311687     | 0.356711     |\n","| conf_noobj | 0.006391     | 0.005852     |\n","+------------+--------------+--------------+\n","Total loss 5.795823097229004\n","---- ETA 0:01:48.090672\n"," 76% 321/425 [01:35<00:30,  3.44it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 99% 422/425 [02:05<00:00,  3.10it/s]\n","---- [Epoch 2/8, Batch 423/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 14           | 28           |\n","| loss       | 2.648143     | 2.505518     |\n","| loss_x     | 0.046315     | 0.076201     |\n","| loss_y     | 0.046741     | 0.062681     |\n","| loss_w     | 0.114741     | 0.104233     |\n","| loss_h     | 0.045387     | 0.057521     |\n","| loss_obj   | 2.373351     | 2.176519     |\n","| loss_cls   | 0.021607     | 0.028364     |\n","| cls_acc    | 66.67%       | 57.97%       |\n","| conf_obj   | 0.339865     | 0.349894     |\n","| conf_noobj | 0.006423     | 0.006149     |\n","+------------+--------------+--------------+\n","Total loss 5.153661727905273\n","---- ETA 0:00:01.205781\n","100% 425/425 [02:06<00:00,  3.35it/s]\n","Current epoch loss : 5.18881 Saved at checkpoints/Yolo_V3_VOC_tiny.pth\n","425\n"," 11% 48/425 [00:14<01:57,  3.21it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 19% 80/425 [00:24<01:34,  3.64it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 24% 101/425 [00:31<01:39,  3.26it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 25% 107/425 [00:32<01:34,  3.35it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 32% 136/425 [00:41<01:28,  3.26it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 140/425 [00:42<01:25,  3.35it/s]\n","---- [Epoch 3/8, Batch 141/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 15           | 30           |\n","| loss       | 2.629547     | 2.840995     |\n","| loss_x     | 0.048750     | 0.084195     |\n","| loss_y     | 0.035620     | 0.057335     |\n","| loss_w     | 0.070036     | 0.090360     |\n","| loss_h     | 0.058137     | 0.071777     |\n","| loss_obj   | 2.384456     | 2.495454     |\n","| loss_cls   | 0.032547     | 0.041872     |\n","| cls_acc    | 45.45%       | 38.18%       |\n","| conf_obj   | 0.397705     | 0.343499     |\n","| conf_noobj | 0.006575     | 0.006344     |\n","+------------+--------------+--------------+\n","Total loss 5.470541954040527\n","---- ETA 0:10:02.460254\n"," 42% 177/425 [00:54<01:21,  3.06it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 66% 281/425 [01:25<00:42,  3.38it/s]\n","---- [Epoch 3/8, Batch 282/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 14           | 28           |\n","| loss       | 2.698058     | 2.514933     |\n","| loss_x     | 0.047466     | 0.058295     |\n","| loss_y     | 0.060530     | 0.080685     |\n","| loss_w     | 0.036663     | 0.067582     |\n","| loss_h     | 0.038030     | 0.051832     |\n","| loss_obj   | 2.497295     | 2.233308     |\n","| loss_cls   | 0.018074     | 0.023231     |\n","| cls_acc    | 75.00%       | 68.18%       |\n","| conf_obj   | 0.340138     | 0.372730     |\n","| conf_noobj | 0.006952     | 0.006669     |\n","+------------+--------------+--------------+\n","Total loss 5.212990760803223\n","---- ETA 0:02:53.087189\n"," 80% 339/425 [01:42<00:24,  3.51it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 99% 422/425 [02:06<00:00,  3.01it/s]\n","---- [Epoch 3/8, Batch 423/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 14           | 28           |\n","| loss       | 2.558210     | 2.310528     |\n","| loss_x     | 0.063977     | 0.072228     |\n","| loss_y     | 0.039952     | 0.056512     |\n","| loss_w     | 0.126759     | 0.076671     |\n","| loss_h     | 0.042481     | 0.030297     |\n","| loss_obj   | 2.265323     | 2.044718     |\n","| loss_cls   | 0.019717     | 0.030103     |\n","| cls_acc    | 73.56%       | 56.04%       |\n","| conf_obj   | 0.379185     | 0.462433     |\n","| conf_noobj | 0.007058     | 0.006881     |\n","+------------+--------------+--------------+\n","Total loss 4.868738174438477\n","---- ETA 0:00:01.811018\n","100% 425/425 [02:07<00:00,  3.32it/s]\n","Current epoch loss : 5.21375 Saved at checkpoints/Yolo_V3_VOC_tiny.pth\n","425\n"," 21% 89/425 [00:26<01:39,  3.38it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 140/425 [00:41<01:24,  3.36it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","\n","---- [Epoch 4/8, Batch 141/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 15           | 30           |\n","| loss       | 2.931579     | 2.861280     |\n","| loss_x     | 0.063305     | 0.075852     |\n","| loss_y     | 0.053633     | 0.081636     |\n","| loss_w     | 0.089973     | 0.077647     |\n","| loss_h     | 0.048945     | 0.058335     |\n","| loss_obj   | 2.653877     | 2.542853     |\n","| loss_cls   | 0.021846     | 0.024958     |\n","| cls_acc    | 71.76%       | 67.05%       |\n","| conf_obj   | 0.306273     | 0.329444     |\n","| conf_noobj | 0.007977     | 0.007054     |\n","+------------+--------------+--------------+\n","Total loss 5.792859077453613\n","---- ETA 0:14:17.494651\n"," 41% 173/425 [00:51<01:17,  3.25it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 41% 174/425 [00:51<01:17,  3.24it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 47% 199/425 [00:58<01:06,  3.42it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 66% 280/425 [01:22<00:42,  3.43it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 66% 281/425 [01:23<00:47,  3.01it/s]\n","---- [Epoch 4/8, Batch 282/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 16           | 32           |\n","| loss       | 2.640395     | 2.406348     |\n","| loss_x     | 0.071827     | 0.064699     |\n","| loss_y     | 0.056657     | 0.057902     |\n","| loss_w     | 0.102557     | 0.092634     |\n","| loss_h     | 0.051797     | 0.070980     |\n","| loss_obj   | 2.324089     | 2.075535     |\n","| loss_cls   | 0.033468     | 0.044599     |\n","| cls_acc    | 43.43%       | 27.36%       |\n","| conf_obj   | 0.325601     | 0.368396     |\n","| conf_noobj | 0.005949     | 0.006108     |\n","+------------+--------------+--------------+\n","Total loss 5.0467424392700195\n","---- ETA 0:03:57.074638\n"," 69% 293/425 [01:27<00:41,  3.18it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 99% 422/425 [02:06<00:00,  3.42it/s]\n","---- [Epoch 4/8, Batch 423/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 13           | 26           |\n","| loss       | 2.512307     | 2.310363     |\n","| loss_x     | 0.046971     | 0.060311     |\n","| loss_y     | 0.037762     | 0.064145     |\n","| loss_w     | 0.069027     | 0.091918     |\n","| loss_h     | 0.085015     | 0.029148     |\n","| loss_obj   | 2.245047     | 2.026194     |\n","| loss_cls   | 0.028485     | 0.038648     |\n","| cls_acc    | 59.32%       | 45.16%       |\n","| conf_obj   | 0.400113     | 0.398433     |\n","| conf_noobj | 0.005898     | 0.006126     |\n","+------------+--------------+--------------+\n","Total loss 4.822669982910156\n","---- ETA 0:00:02.412815\n","100% 425/425 [02:07<00:00,  3.34it/s]\n","Current epoch loss : 5.22293 Saved at checkpoints/Yolo_V3_VOC_tiny.pth\n","425\n"," 18% 76/425 [00:23<01:45,  3.32it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 21% 90/425 [00:27<01:41,  3.30it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 23% 98/425 [00:29<01:35,  3.41it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 140/425 [00:41<01:25,  3.35it/s]\n","---- [Epoch 5/8, Batch 141/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 12           | 24           |\n","| loss       | 2.934703     | 2.737969     |\n","| loss_x     | 0.053975     | 0.056340     |\n","| loss_y     | 0.062113     | 0.069306     |\n","| loss_w     | 0.100067     | 0.076919     |\n","| loss_h     | 0.053203     | 0.070552     |\n","| loss_obj   | 2.635078     | 2.424944     |\n","| loss_cls   | 0.030267     | 0.039907     |\n","| cls_acc    | 49.15%       | 42.37%       |\n","| conf_obj   | 0.327275     | 0.350282     |\n","| conf_noobj | 0.005978     | 0.006087     |\n","+------------+--------------+--------------+\n","Total loss 5.672671794891357\n","---- ETA 0:18:33.786070\n"," 34% 145/425 [00:42<01:17,  3.63it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 38% 162/425 [00:47<01:12,  3.61it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 66% 281/425 [01:20<00:37,  3.88it/s]\n","---- [Epoch 5/8, Batch 282/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 10           | 20           |\n","| loss       | 2.844354     | 2.546456     |\n","| loss_x     | 0.054251     | 0.072708     |\n","| loss_y     | 0.039439     | 0.074664     |\n","| loss_w     | 0.109920     | 0.068363     |\n","| loss_h     | 0.097780     | 0.047697     |\n","| loss_obj   | 2.517508     | 2.251509     |\n","| loss_cls   | 0.025456     | 0.031515     |\n","| cls_acc    | 62.96%       | 63.64%       |\n","| conf_obj   | 0.342078     | 0.418442     |\n","| conf_noobj | 0.006130     | 0.006739     |\n","+------------+--------------+--------------+\n","Total loss 5.390810012817383\n","---- ETA 0:05:00.345060\n"," 78% 332/425 [01:35<00:26,  3.46it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 98% 416/425 [01:59<00:02,  3.33it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 99% 422/425 [02:00<00:00,  3.91it/s]\n","---- [Epoch 5/8, Batch 423/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 10           | 20           |\n","| loss       | 2.930600     | 2.747971     |\n","| loss_x     | 0.070976     | 0.054400     |\n","| loss_y     | 0.045926     | 0.056295     |\n","| loss_w     | 0.077446     | 0.076229     |\n","| loss_h     | 0.047484     | 0.101202     |\n","| loss_obj   | 2.660619     | 2.421109     |\n","| loss_cls   | 0.028150     | 0.038736     |\n","| cls_acc    | 55.07%       | 40.85%       |\n","| conf_obj   | 0.359341     | 0.364446     |\n","| conf_noobj | 0.007154     | 0.006920     |\n","+------------+--------------+--------------+\n","Total loss 5.678571701049805\n","---- ETA 0:00:02.988092\n","100% 425/425 [02:01<00:00,  3.50it/s]\n","Current epoch loss : 5.22657 Saved at checkpoints/Yolo_V3_VOC_tiny.pth\n","425\n","  8% 35/425 [00:10<01:57,  3.33it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 140/425 [00:40<01:22,  3.47it/s]\n","---- [Epoch 6/8, Batch 141/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 15           | 30           |\n","| loss       | 2.503345     | 2.513068     |\n","| loss_x     | 0.056898     | 0.094853     |\n","| loss_y     | 0.041940     | 0.067735     |\n","| loss_w     | 0.070482     | 0.102739     |\n","| loss_h     | 0.075826     | 0.057510     |\n","| loss_obj   | 2.228300     | 2.147679     |\n","| loss_cls   | 0.029899     | 0.042552     |\n","| cls_acc    | 57.63%       | 40.98%       |\n","| conf_obj   | 0.403503     | 0.405870     |\n","| conf_noobj | 0.005876     | 0.006061     |\n","+------------+--------------+--------------+\n","Total loss 5.016413688659668\n","---- ETA 0:22:36.807130\n"," 46% 197/425 [00:57<01:05,  3.45it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 66% 281/425 [01:21<00:38,  3.79it/s]\n","---- [Epoch 6/8, Batch 282/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 11           | 22           |\n","| loss       | 2.865721     | 2.521135     |\n","| loss_x     | 0.051897     | 0.078480     |\n","| loss_y     | 0.050576     | 0.077289     |\n","| loss_w     | 0.121629     | 0.075140     |\n","| loss_h     | 0.063335     | 0.053352     |\n","| loss_obj   | 2.550692     | 2.202157     |\n","| loss_cls   | 0.027593     | 0.034718     |\n","| cls_acc    | 57.14%       | 37.88%       |\n","| conf_obj   | 0.286450     | 0.329436     |\n","| conf_noobj | 0.006545     | 0.006670     |\n","+------------+--------------+--------------+\n","Total loss 5.3868560791015625\n","---- ETA 0:06:02.120314\n"," 86% 365/425 [01:44<00:15,  3.84it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 90% 381/425 [01:49<00:11,  3.68it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 94% 401/425 [01:54<00:06,  3.55it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 95% 404/425 [01:55<00:05,  3.66it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 98% 417/425 [01:59<00:02,  3.42it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 99% 422/425 [02:00<00:00,  3.54it/s]\n","---- [Epoch 6/8, Batch 423/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 12           | 24           |\n","| loss       | 2.459722     | 2.483335     |\n","| loss_x     | 0.065255     | 0.072392     |\n","| loss_y     | 0.042002     | 0.066386     |\n","| loss_w     | 0.065749     | 0.065961     |\n","| loss_h     | 0.063578     | 0.065202     |\n","| loss_obj   | 2.198544     | 2.182426     |\n","| loss_cls   | 0.024594     | 0.030968     |\n","| cls_acc    | 56.16%       | 49.32%       |\n","| conf_obj   | 0.405822     | 0.402837     |\n","| conf_noobj | 0.006606     | 0.006845     |\n","+------------+--------------+--------------+\n","Total loss 4.943057060241699\n","---- ETA 0:00:03.563158\n","100% 425/425 [02:01<00:00,  3.50it/s]\n","Current epoch loss : 5.18069 Saved at checkpoints/Yolo_V3_VOC_tiny.pth\n","425\n","  0% 0/425 [00:00<?, ?it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 10% 41/425 [00:12<01:50,  3.47it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 10% 43/425 [00:12<01:43,  3.69it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 28% 120/425 [00:34<01:28,  3.43it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 140/425 [00:40<01:28,  3.22it/s]\n","---- [Epoch 7/8, Batch 141/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 14           | 28           |\n","| loss       | 2.404650     | 2.286949     |\n","| loss_x     | 0.071231     | 0.078710     |\n","| loss_y     | 0.039744     | 0.058240     |\n","| loss_w     | 0.053966     | 0.059360     |\n","| loss_h     | 0.039907     | 0.051155     |\n","| loss_obj   | 2.168693     | 2.000876     |\n","| loss_cls   | 0.031109     | 0.038607     |\n","| cls_acc    | 47.22%       | 45.83%       |\n","| conf_obj   | 0.381085     | 0.432737     |\n","| conf_noobj | 0.006518     | 0.006510     |\n","+------------+--------------+--------------+\n","Total loss 4.691598892211914\n","---- ETA 0:26:41.125210\n"," 61% 259/425 [01:14<00:50,  3.31it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 61% 261/425 [01:14<00:45,  3.59it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 66% 281/425 [01:20<00:39,  3.69it/s]\n","---- [Epoch 7/8, Batch 282/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 10           | 20           |\n","| loss       | 3.777524     | 3.516057     |\n","| loss_x     | 0.074708     | 0.069222     |\n","| loss_y     | 0.064361     | 0.067279     |\n","| loss_w     | 0.261884     | 0.135743     |\n","| loss_h     | 0.288134     | 0.128567     |\n","| loss_obj   | 3.065676     | 3.086965     |\n","| loss_cls   | 0.022761     | 0.028281     |\n","| cls_acc    | 70.00%       | 57.53%       |\n","| conf_obj   | 0.308619     | 0.299039     |\n","| conf_noobj | 0.007093     | 0.006850     |\n","+------------+--------------+--------------+\n","Total loss 7.293581008911133\n","---- ETA 0:07:03.322349\n"," 99% 422/425 [02:00<00:00,  3.70it/s]\n","---- [Epoch 7/8, Batch 423/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 11           | 22           |\n","| loss       | 2.941580     | 2.752223     |\n","| loss_x     | 0.049742     | 0.068987     |\n","| loss_y     | 0.032341     | 0.068846     |\n","| loss_w     | 0.209339     | 0.142556     |\n","| loss_h     | 0.057066     | 0.038493     |\n","| loss_obj   | 2.569561     | 2.401180     |\n","| loss_cls   | 0.023531     | 0.032162     |\n","| cls_acc    | 71.70%       | 54.72%       |\n","| conf_obj   | 0.352356     | 0.352683     |\n","| conf_noobj | 0.006714     | 0.006423     |\n","+------------+--------------+--------------+\n","Total loss 5.693802833557129\n","---- ETA 0:00:04.137007\n","100% 424/425 [02:00<00:00,  3.76it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","100% 425/425 [02:01<00:00,  3.50it/s]\n","Current epoch loss : 5.22843 Saved at checkpoints/Yolo_V3_VOC_tiny.pth\n","425\n","  2% 7/425 [00:02<01:59,  3.51it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_000763.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 25% 106/425 [00:30<01:25,  3.73it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004172.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005145.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 32% 134/425 [00:38<01:22,  3.52it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_004562.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 33% 140/425 [00:39<01:20,  3.55it/s]\n","---- [Epoch 8/8, Batch 141/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 16           | 32           |\n","| loss       | 2.752098     | 2.898855     |\n","| loss_x     | 0.075521     | 0.084365     |\n","| loss_y     | 0.056618     | 0.115009     |\n","| loss_w     | 0.095446     | 0.095000     |\n","| loss_h     | 0.046564     | 0.070138     |\n","| loss_obj   | 2.448077     | 2.497219     |\n","| loss_cls   | 0.029872     | 0.037124     |\n","| cls_acc    | 53.23%       | 48.39%       |\n","| conf_obj   | 0.300245     | 0.297244     |\n","| conf_noobj | 0.006031     | 0.005970     |\n","+------------+--------------+--------------+\n","Total loss 5.65095329284668\n","---- ETA 0:30:44.990189\n"," 41% 174/425 [00:50<01:16,  3.30it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_007355.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 66% 281/425 [01:21<00:41,  3.47it/s]\n","---- [Epoch 8/8, Batch 282/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 13           | 26           |\n","| loss       | 2.322881     | 2.499221     |\n","| loss_x     | 0.058398     | 0.084650     |\n","| loss_y     | 0.056118     | 0.071163     |\n","| loss_w     | 0.090798     | 0.051486     |\n","| loss_h     | 0.025440     | 0.036130     |\n","| loss_obj   | 2.072479     | 2.230385     |\n","| loss_cls   | 0.019647     | 0.025408     |\n","| cls_acc    | 66.04%       | 61.82%       |\n","| conf_obj   | 0.406719     | 0.360445     |\n","| conf_noobj | 0.006580     | 0.006411     |\n","+------------+--------------+--------------+\n","Total loss 4.822101593017578\n","---- ETA 0:08:05.498648\n"," 77% 329/425 [01:34<00:28,  3.42it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005262.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 98% 416/425 [01:59<00:02,  3.62it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_008051.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n"," 99% 422/425 [02:00<00:00,  3.64it/s]\n","---- [Epoch 8/8, Batch 423/425] ----\n","+------------+--------------+--------------+\n","| Metrics    | YOLO Layer 0 | YOLO Layer 1 |\n","+------------+--------------+--------------+\n","| grid_size  | 10           | 20           |\n","| loss       | 2.829465     | 2.704687     |\n","| loss_x     | 0.054968     | 0.068352     |\n","| loss_y     | 0.042694     | 0.063719     |\n","| loss_w     | 0.104184     | 0.046421     |\n","| loss_h     | 0.063672     | 0.051014     |\n","| loss_obj   | 2.532667     | 2.438046     |\n","| loss_cls   | 0.031279     | 0.037134     |\n","| cls_acc    | 54.24%       | 48.33%       |\n","| conf_obj   | 0.331764     | 0.332600     |\n","| conf_noobj | 0.006458     | 0.006546     |\n","+------------+--------------+--------------+\n","Total loss 5.534152030944824\n","---- ETA 0:00:04.713284\n","100% 425/425 [02:01<00:00,  3.49it/s]\n","Current epoch loss : 5.21267 Saved at checkpoints/Yolo_V3_VOC_tiny.pth\n","\n","---- Evaluating Model ----\n","Detecting objects:  89% 95/107 [00:25<00:03,  3.62it/s]/content/utils/datasets.py:107: UserWarning: loadtxt: Empty input file: \"/content/dataset/VOC2012/labels/2008_005953.txt\"\n","  boxes = torch.from_numpy(np.loadtxt(label_path).reshape(-1, 5))\n","Detecting objects: 100% 107/107 [00:29<00:00,  3.66it/s]\n","Computing AP: 100% 20/20 [00:00<00:00, 836.72it/s]\n","+-------+-------------+---------+\n","| Index | Class name  | AP      |\n","+-------+-------------+---------+\n","| 0     | aeroplane   | 0.05062 |\n","| 1     | bicycle     | 0.17489 |\n","| 2     | bird        | 0.00004 |\n","| 3     | boat        | 0.00032 |\n","| 4     | bottle      | 0.00517 |\n","| 5     | bus         | 0.45468 |\n","| 6     | car         | 0.17964 |\n","| 7     | cat         | 0.14579 |\n","| 8     | chair       | 0.11815 |\n","| 9     | cow         | 0.01031 |\n","| 10    | diningtable | 0.00150 |\n","| 11    | dog         | 0.05461 |\n","| 12    | horse       | 0.00000 |\n","| 13    | motorbike   | 0.03224 |\n","| 14    | person      | 0.42763 |\n","| 15    | pottedplant | 0.00484 |\n","| 16    | sheep       | 0.07316 |\n","| 17    | sofa        | 0.00954 |\n","| 18    | train       | 0.00103 |\n","| 19    | tvmonitor   | 0.19278 |\n","+-------+-------------+---------+\n","---- mAP 0.09684619983718325\n"]}],"source":["! python train.py --num_epochs 8 --batch_size 32 --data_config config/VOC.data --model_def config/yolov3-tiny.cfg --pretrained_path checkpoints/yolov3-tiny.weights --save_path checkpoints/Yolo_V3_VOC_tiny.pth"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyOj7K3VV5M6MBLYkWOwpvHm"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}